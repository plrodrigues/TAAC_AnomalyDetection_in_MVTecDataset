{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from src.commons.dataset import TinyImageNetDataset\n",
    "from src.commons.constants import DATA_PATH, DIR_SEP\n",
    "\n",
    "import logging, os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import vit_pytorch as vit\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECKPOINT PATH:  ..\\src\\commons\\models\n",
      "Total parameters: 8.53e+06\n",
      "Dataset size: 100000\n",
      "DEVICE: cuda\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |   34351 KB |   34351 KB |   34351 KB |       0 B  |\n",
      "|       from large pool |   29696 KB |   29696 KB |   29696 KB |       0 B  |\n",
      "|       from small pool |    4655 KB |    4655 KB |    4655 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |   34351 KB |   34351 KB |   34351 KB |       0 B  |\n",
      "|       from large pool |   29696 KB |   29696 KB |   29696 KB |       0 B  |\n",
      "|       from small pool |    4655 KB |    4655 KB |    4655 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |   47104 KB |   47104 KB |   47104 KB |       0 B  |\n",
      "|       from large pool |   40960 KB |   40960 KB |   40960 KB |       0 B  |\n",
      "|       from small pool |    6144 KB |    6144 KB |    6144 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   12753 KB |   19354 KB |   39840 KB |   27087 KB |\n",
      "|       from large pool |   11264 KB |   18432 KB |   35840 KB |   24576 KB |\n",
      "|       from small pool |    1489 KB |    1952 KB |    4000 KB |    2511 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |      46    |      46    |      46    |       0    |\n",
      "|       from large pool |      12    |      12    |      12    |       0    |\n",
      "|       from small pool |      34    |      34    |      34    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |      46    |      46    |      46    |       0    |\n",
      "|       from large pool |      12    |      12    |      12    |       0    |\n",
      "|       from small pool |      34    |      34    |      34    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       5    |       5    |       5    |       0    |\n",
      "|       from large pool |       2    |       2    |       2    |       0    |\n",
      "|       from small pool |       3    |       3    |       3    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       3    |       3    |       5    |       2    |\n",
      "|       from large pool |       1    |       1    |       2    |       1    |\n",
      "|       from small pool |       2    |       2    |       3    |       1    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "# https://github.com/lucidrains/vit-pytorch#parameters\n",
    "\n",
    "\n",
    "# Define training parameters\n",
    "BATCH_SIZE = 1024\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 50\n",
    "CHECKPOINT_PATH = \"..\" + DIR_SEP + os.path.join(\"src\", \"commons\", \"models\")\n",
    "print(\"CHECKPOINT PATH: \", CHECKPOINT_PATH)\n",
    "\n",
    "# Instantiate model, optimizer and loss function\n",
    "model = vit.SimpleViT(\n",
    "    image_size = 64,\n",
    "    patch_size = 4,\n",
    "    num_classes = 200,\n",
    "    dim = 512,\n",
    "    depth = 4,\n",
    "    heads = 8,\n",
    "    mlp_dim = 1024\n",
    ")\n",
    "\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad) :.2e}\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Instantiate dataset\n",
    "transf = None\n",
    "dataset = TinyImageNetDataset(\"..\" + DIR_SEP + DATA_PATH, transforms=transf)\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "\n",
    "# Split dataset in train/test/validation sets\n",
    "\n",
    "train_data, test_data, val_data = torch.utils.data.random_split(dataset, [0.8, 0.1, 0.1])\n",
    "\n",
    "# Create dataloaders\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "valid_loader = torch.utils.data.DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Attempt training on GPU\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "# elif torch.backends.mps.is_available():\n",
    "#     DEVICE = torch.device('mps')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "print('DEVICE:', DEVICE)\n",
    "\n",
    "# Send to device\n",
    "model = model.to(DEVICE)\n",
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate code, copy-paste from previous class work\n",
    "def evaluate(model, data_loader, **kwargs):\n",
    "    loss_fn = kwargs.get(\"loss_fn\", nn.CrossEntropyLoss())\n",
    "    device = kwargs.get(\"device\", torch.device(\"cpu\"))\n",
    "    \n",
    "    model.eval() # set model to evaluation mode\n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    avg_loss, avg_acc = 0., 0.\n",
    "    for i, batch in pbar:\n",
    "\n",
    "        data, targets = batch[\"inputs\"], batch[\"targets\"]\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        \n",
    "        model.zero_grad() # initialize gradients to zero\n",
    "        with torch.no_grad(): # no need to compute gradients\n",
    "            logits = model(data)\n",
    "            preds = torch.softmax(logits)\n",
    "            pred_cats = preds.argmax(dim=1)\n",
    "            acc = (pred_cats == targets).float().mean()\n",
    "           \n",
    "        loss = loss_fn(logits, targets)\n",
    "        avg_loss += loss.item()\n",
    "        avg_acc += acc.item()\n",
    "        pbar.set_description(f\"loss = {loss:.3f} | acc = {acc:.3f}\")\n",
    "    avg_loss /= len(data_loader)\n",
    "    avg_acc /= len(data_loader)\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "def fit(model, train_loader, val_loader, optimizer, **kwargs):\n",
    "    loss_fn = kwargs.get(\"loss_fn\", nn.CrossEntropyLoss())\n",
    "    device = kwargs.get(\"device\", torch.device(\"cpu\"))\n",
    "    num_epochs = kwargs.get(\"num_epochs\", 100)\n",
    "\n",
    "    train_loss_hist, val_loss_hist = [], []\n",
    "    train_acc_hist, val_acc_hist = [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "        model.train() # set model to training mode\n",
    "        train_loss, train_acc = 0., 0.\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "        for i, batch in pbar:\n",
    "            \n",
    "            data, targets = batch[\"inputs\"], batch[\"targets\"]\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "    \n",
    "            logging.debug(f\"Batch - Input: {data.shape, type(data)} Target: {targets.shape, type(targets)}\")\n",
    "\n",
    "            model.zero_grad() # initialize gradients to zero\n",
    "            logits = model(data) # forward pass\n",
    "\n",
    "            logging.debug(f\"Logits - {logits.shape}, {type(logits)}\")\n",
    "\n",
    "            loss = loss_fn(logits, targets) # loss computation\n",
    "            loss.backward() # computing gradients (backward pass)\n",
    "            \n",
    "            optimizer.step() # updating the parameters of the model\n",
    "            # accuracy computation\n",
    "            with torch.no_grad():\n",
    "                preds = torch.softmax(logits)\n",
    "                pred_cats = preds.argmax(dim=1)\n",
    "                acc = (pred_cats == targets).float().mean()\n",
    "    \n",
    "            # pop computational graph\n",
    "            train_loss += loss.item()\n",
    "            train_acc += acc.item() \n",
    "            pbar.set_description(f\"loss = {loss:.3f} | acc = {acc:.3f}\")\n",
    "        \n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc /= len(train_loader)\n",
    "        print(f\"Train loss: {train_loss:.3f} | train acc = {train_acc:.3f}\")\n",
    "        train_loss_hist.append(train_loss)\n",
    "        train_acc_hist.append(train_acc) \n",
    "        \n",
    "        val_loss, val_acc = evaluate(model, val_loader, loss_fn=loss_fn, device=device)\n",
    "        print(f\"Validation loss: {val_loss:.3f} | val acc = {val_acc:.3f}\")\n",
    "        val_loss_hist.append(val_loss)\n",
    "        val_acc_hist.append(val_acc)\n",
    "        \n",
    "    return train_loss_hist, val_loss_hist, train_acc_hist, val_acc_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "train_loss, val_loss, train_acc, val_acc = fit(model, train_loader, valid_loader, optimizer, num_epochs=NUM_EPOCHS, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.randn(5, 3, 64, 64).to(DEVICE)\n",
    "\n",
    "preds = model(img) \n",
    "pred_cat = preds.argmax(dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('tapc-project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8232baa799334afe543e2acd393bb3cae9a3498fd20d98e378d09c9bddfb174e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
